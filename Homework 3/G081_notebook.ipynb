{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the csv dataset\n",
    "df = pd.read_csv('parkinsons.csv', delimiter =',')\n",
    "\n",
    "# Separate the features from the outcome\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_formats = ['svg']\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "# Igonre Converge warning\n",
    "warnings.filterwarnings(action='ignore', category=ConvergenceWarning)\n",
    "\n",
    "runs = 10\n",
    "neurons = 10\n",
    "hidden_layers = 2\n",
    "\n",
    "lr_mae, mlp_mae, mlp_relu_mae = [], [], []\n",
    "for run in range(runs):\n",
    "    # Split the data in training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=(run+1))\n",
    "    # Linear Regression model\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train, y_train)\n",
    "    pred_lr = lr.predict(X_test)\n",
    "    # Compute MAE\n",
    "    lr_mae.append(metrics.mean_absolute_error(y_test, pred_lr))\n",
    "    # MLP model with no activation functiom\n",
    "    mlp = MLPRegressor(hidden_layer_sizes=[neurons for _ in range(hidden_layers)], activation='identity', random_state=0)\n",
    "    mlp.fit(X_train, y_train)\n",
    "    pred_mlp = mlp.predict(X_test)\n",
    "    # Compute MAE\n",
    "    mlp_mae.append(metrics.mean_absolute_error(y_test, pred_mlp))\n",
    "    # MLP model with relu activation function\n",
    "    mlp = MLPRegressor(hidden_layer_sizes=[neurons for _ in range(hidden_layers)], random_state=0)\n",
    "    mlp.fit(X_train, y_train)\n",
    "    pred_mlp_relu = mlp.predict(X_test)\n",
    "    # Compute MAE\n",
    "    mlp_relu_mae.append(metrics.mean_absolute_error(y_test, pred_mlp_relu))\n",
    "maes = [lr_mae, mlp_mae, mlp_relu_mae]\n",
    "\n",
    "# Plot the test MAE boxplot for each model\n",
    "labels = ['Linear Regression', 'MLP using no function', 'MLP using ReLU']\n",
    "colors = ['peachpuff', 'orange', 'gold']\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_ylabel ('Test MAE')\n",
    "\n",
    "bplot = ax.boxplot (maes, patch_artist=True, tick_labels=labels)\n",
    "for patch, color in zip(bplot['boxes'], colors):\n",
    "    patch.set_facecolor(color)\n",
    "for median in bplot['medians']:\n",
    "    median.set_color('black')\n",
    "\n",
    "plt.show ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_formats = ['svg']\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "l2_penalties = [0.0001, 0.001, 0.01]\n",
    "batch_sizes = [32, 64, 128]\n",
    "learning_rates = [0.001, 0.01, 0.1]\n",
    "hyperparameters = {'alpha':l2_penalties, 'batch_size':batch_sizes, 'learning_rate_init':learning_rates,}\n",
    "\n",
    "# Split the data in training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=0)\n",
    "\n",
    "# MLP model with relu activation function (default)\n",
    "mlp = MLPRegressor(hidden_layer_sizes=[neurons for _ in range(hidden_layers)], random_state=0)\n",
    "\n",
    "# Perform a grid search to tune the given hyperparameters\n",
    "search = GridSearchCV(mlp, hyperparameters, scoring='neg_mean_absolute_error')\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "# Best combination of hyperparameters\n",
    "print(f'Best combination: {str(search.best_params_).replace('alpha', 'L2 penalty')}')\n",
    "\n",
    "# Grid Search results dictionary\n",
    "results = search.cv_results_\n",
    "\n",
    "# get the coordinates for each axis     \n",
    "l2_penalties_order, learning_rates_order, batch_sizes_order = [], [], []\n",
    "for combination in results['params']:\n",
    "    l2_penalties_order.append(combination['alpha'])\n",
    "    batch_sizes_order.append(combination['batch_size'])\n",
    "    learning_rates_order.append(combination['learning_rate_init'])\n",
    "\n",
    "# Plots the MAE for each combination of hyperparameters\n",
    "# Uses a colormap to simulate a 4D plot\n",
    "fig = plt.figure(figsize=(8,6.4))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# minus results because by convention, higher return values are better than lower return values\n",
    "img = ax.scatter(l2_penalties_order, batch_sizes_order, learning_rates_order, c=-results['mean_test_score'], cmap='jet')\n",
    "ax.set(xlabel='L2 penalties', ylabel='Batch sizes', zlabel='Learning Rates', xticks=l2_penalties, yticks=batch_sizes, zticks=learning_rates)\n",
    "fig.colorbar(img, label='Mean Absoulute Error', location='top')\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
